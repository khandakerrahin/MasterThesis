% book
% Required fields: author or editor, title, publisher, year. 
% Optional fields: volume or number, series, address, edition, month, note.

% article
% Required fields: author, title, journal, year. 
% Optional fields: volume, number, pages, month, note.

% conference
% same as inproceedings
% Required fields: author, title, booktitle, year. 
% Optional fields: editor, volume or number, series, pages, address, month, organization, publisher, note

% website
% as misc
% Required fields: none. 
% Optional fields: author, title, howpublished, month, year, note.


% 1. TOGA

@inproceedings{gabriel_ryan_toga_2022,
	title = {{TOGA}: A Neural Method for Test Oracle Generation},
	volume = {2022-May},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133519784&doi=10.1145%2f3510003.3510141&partnerID=40&md5=6cc5007a3c7ed9be6a7c35556b9baa1f},
	doi = {10.1145/3510003.3510141},
	abstract = {Testing is widely recognized as an important stage of the software development lifecycle. Effective software testing can provide benefits such as bug finding, preventing regressions, and documentation. In terms of documentation, unit tests express a unit's intended functionality, as conceived by the developer. A test oracle, typically expressed as an condition, documents the intended behavior of a unit under a given test prefix. Synthesizing a functional test oracle is a challenging problem, as it must capture the intended functionality rather than the implemented functionality. In this paper, we propose {TOGA} (a neural method for Test Oracle {GenerAtion}), a unified transformer-based neural approach to infer both exceptional and assertion test oracles based on the context of the focal method. Our approach can handle units with ambiguous or missing documentation, and even units with a missing implementation. We evaluate our approach on both oracle inference accuracy and functional bug-finding. Our technique improves accuracy by 33\% over existing oracle inference approaches, achieving 96\% over-all accuracy on a held out test dataset. Furthermore, we show that when integrated with a automated test generation tool ({EvoSuite}), our approach finds 57 real world bugs in large-scale Java programs, including 30 bugs that are not found by any other automated testing method in our evaluation. © 2022 {ACM}.},
	pages = {2130 -- 2141},
	booktitle = {Proceedings - International Conference on Software Engineering},
	author = {{Gabriel Ryan} and {Todd Mytkowicz} and {Shuvendu K. Lahiri} and {Elizabeth Dinella}},
	date = {2022},
	note = {Type: Conference paper},
	keywords = {Language model, Software testing, Learning systems, Machine learning, Machine-learning, Software design, Program debugging, Statistical tests, Software testings, Electric transformer testing, Bug finding, Condition, Functional test, Life cycle, Software development life-cycle, Test oracles, Transformer, Unit tests},
	annotation = {Cited by: 2; All Open Access, Green Open Access},
	file = {Submitted Version:/home/shaker/Zotero/storage/525P4QRC/Dinella et al. - 2022 - TOGA A Neural Method for Test Oracle Generation.pdf:application/pdf},
}

@inproceedings{tufano_generating_2022,
	location = {New York, {NY}, {USA}},
	title = {Generating accurate assert statements for unit test cases using pretrained transformers},
	isbn = {978-1-4503-9286-0},
	url = {https://dl.acm.org/doi/10.1145/3524481.3527220},
	doi = {10.1145/3524481.3527220},
	series = {{AST} '22},
	abstract = {Unit testing represents the foundational basis of the software testing pyramid, beneath integration and end-to-end testing. Automated software testing researchers have proposed a variety of techniques to assist developers in this time-consuming task. In this paper we present an approach to support developers in writing unit test cases by generating accurate and useful assert statements. Our approach is based on a state-of-the-art transformer model initially pretrained on an English textual corpus. This semantically rich model is then trained in a semi-supervised fashion on a large corpus of source code. Finally, we finetune this model on the task of generating assert statements for unit tests. The resulting model is able to generate accurate assert statements for a given method under test. In our empirical evaluation, the model was able to predict the exact assert statements written by developers in 62\% of the cases in the first attempt. The results show 80\% relative improvement for top-1 accuracy over the previous {RNN}-based approach in the literature, as well as 33\% improvement over the recent Transformer-based T5 approach. We also show the substantial impact of the pretraining process on the performances of our model, as well as comparing it with assert auto-completion task. Finally, we demonstrate how our approach can be used to augment {EvoSuite} test cases, with additional asserts leading to improved test coverage.},
	pages = {54--64},
	booktitle = {Proceedings of the 3rd {ACM}/{IEEE} International Conference on Automation of Software Test},
	publisher = {Association for Computing Machinery},
	author = {Tufano, Michele and Drain, Dawn and Svyatkovskiy, Alexey and Sundaresan, Neel},
	urldate = {2023-06-08},
	date = {2022-07-19},
	keywords = {neural networks, software testing, unit test},
	file = {Full Text PDF:/home/shaker/Zotero/storage/DR79V28J/Tufano et al. - 2022 - Generating accurate assert statements for unit tes.pdf:application/pdf},
}

@misc{nie_learning_2023,
	title = {Learning Deep Semantics for Test Completion},
	url = {http://arxiv.org/abs/2302.10166},
	abstract = {Writing tests is a time-consuming yet essential task during software development. We propose to leverage recent advances in deep learning for text and code generation to assist developers in writing tests. We formalize the novel task of test completion to automatically complete the next statement in a test method based on the context of prior statements and the code under test. We develop {TeCo} -- a deep learning model using code semantics for test completion. The key insight underlying {TeCo} is that predicting the next statement in a test method requires reasoning about code execution, which is hard to do with only syntax-level data that existing code completion models use. {TeCo} extracts and uses six kinds of code semantics data, including the execution result of prior statements and the execution context of the test method. To provide a testbed for this new task, as well as to evaluate {TeCo}, we collect a corpus of 130,934 test methods from 1,270 open-source Java projects. Our results show that {TeCo} achieves an exact-match accuracy of 18, which is 29\% higher than the best baseline using syntax-level data only. When measuring functional correctness of generated next statement, {TeCo} can generate runnable code in 29\% of the cases compared to 18\% obtained by the best baseline. Moreover, {TeCo} is significantly better than prior work on test oracle generation.},
	number = {{arXiv}:2302.10166},
	publisher = {{arXiv}},
	author = {Nie, Pengyu and Banerjee, Rahul and Li, Junyi Jessy and Mooney, Raymond J. and Gligoric, Milos},
	urldate = {2023-06-09},
	date = {2023-03-07},
	eprinttype = {arxiv},
	eprint = {2302.10166 [cs]},
	keywords = {Computer Science - Software Engineering, Computer Science - Computation and Language, Computer Science - Machine Learning},
	annotation = {Comment: Accepted as a conference paper in {ICSE} 2023},
	file = {arXiv.org Snapshot:/home/shaker/Zotero/storage/HYZ3FLC8/2302.html:text/html;Full Text PDF:/home/shaker/Zotero/storage/8STUDGVP/Nie et al. - 2023 - Learning Deep Semantics for Test Completion.pdf:application/pdf},
}

@inproceedings{vaswani_attention_2017,
	title = {Attention is All you Need},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
	abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 {BLEU} {onEnglish}-to-German translation, improving over the existing best ensemble result by over 1 {BLEU}. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 {BLEU}, achieving a {BLEU} score of 41.1.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
	urldate = {2023-10-01},
	date = {2017},
	file = {Full Text PDF:/home/shaker/Zotero/storage/VLVDK8ZJ/Vaswani et al. - 2017 - Attention is All you Need.pdf:application/pdf},
}